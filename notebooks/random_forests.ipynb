{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Brian McCollum, Estefan Gonzales, Cyrus McCormick\n","## CS429 Project1: Random Forests"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-02-05T06:13:57.789159Z","iopub.status.busy":"2023-02-05T06:13:57.788738Z","iopub.status.idle":"2023-02-05T06:13:58.284299Z","shell.execute_reply":"2023-02-05T06:13:58.282905Z","shell.execute_reply.started":"2023-02-05T06:13:57.789125Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","from enum import Enum\n","from sklearn.model_selection import train_test_split\n","\n","from collections import defaultdict\n","\n","import src.cart\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-02-05T06:37:46.290385Z","iopub.status.busy":"2023-02-05T06:37:46.289553Z","iopub.status.idle":"2023-02-05T06:37:46.347309Z","shell.execute_reply":"2023-02-05T06:37:46.345766Z","shell.execute_reply.started":"2023-02-05T06:37:46.290330Z"},"trusted":true},"outputs":[],"source":["sample_df = pd.read_csv(\"dataset/agaricus-lepiota - sample_solution.csv\")\n","test_df = pd.read_csv(\"dataset/agaricus-lepiota - testing.csv\")\n","train_df = pd.read_csv(\"dataset/agaricus-lepiota - training.csv\")\n","# split the dataframe into training and validation sets\n","train_df, validation_df = train_test_split(train_df, test_size=0.2)"]},{"cell_type":"markdown","metadata":{},"source":["### Node class"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-02-05T06:10:40.384709Z","iopub.status.busy":"2023-02-05T06:10:40.384361Z","iopub.status.idle":"2023-02-05T06:10:40.391638Z","shell.execute_reply":"2023-02-05T06:10:40.390603Z","shell.execute_reply.started":"2023-02-05T06:10:40.384678Z"},"trusted":true},"outputs":[],"source":["class AttrNode:\n","    def __init__(self, name: str, info_gain: float, is_leaf: bool=False) -> None:\n","        self.name: str = name\n","        self.info_gain: float = info_gain\n","        self.children: dict = dict()\n","        self.is_leaf: bool = is_leaf\n","\n","    def __str__(self) -> str:\n","        return f\"attribute=[name:{self.name}, info_gain:{self.info_gain}], is_leaf={self.is_leaf}]\""]},{"cell_type":"markdown","metadata":{},"source":["## Information Gain"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-02-05T06:10:40.398226Z","iopub.status.busy":"2023-02-05T06:10:40.397679Z","iopub.status.idle":"2023-02-05T06:10:40.407581Z","shell.execute_reply":"2023-02-05T06:10:40.406167Z","shell.execute_reply.started":"2023-02-05T06:10:40.398191Z"},"trusted":true},"outputs":[],"source":["class iGainType(Enum):\n","    entropy = 0\n","    gini = 1\n","    misclass = 2"]},{"cell_type":"markdown","metadata":{},"source":["### Gini Index\n","$1 - \\sum_{i=1}^{m} p_i^2$"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-02-05T06:10:40.420988Z","iopub.status.busy":"2023-02-05T06:10:40.419705Z","iopub.status.idle":"2023-02-05T06:10:40.427821Z","shell.execute_reply":"2023-02-05T06:10:40.426218Z","shell.execute_reply.started":"2023-02-05T06:10:40.420931Z"},"trusted":true},"outputs":[],"source":["def gini_index(dataset, classifier):\n","    n = len(dataset.index)\n","    prob = 0\n","    class_dict = defaultdict(int)\n","    for datum in dataset.loc[:, classifier]:\n","        class_dict[datum] += 1\n","    for key in class_dict:\n","        prob += ((class_dict[key] / n) ** 2)\n","    return 1 - prob"]},{"cell_type":"markdown","metadata":{},"source":["### Entropy\n","$\\sum_{i=1}^{m} - p_i log_2 p_i$"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-02-05T06:10:40.438007Z","iopub.status.busy":"2023-02-05T06:10:40.437528Z","iopub.status.idle":"2023-02-05T06:10:40.448515Z","shell.execute_reply":"2023-02-05T06:10:40.447408Z","shell.execute_reply.started":"2023-02-05T06:10:40.437930Z"},"trusted":true},"outputs":[],"source":["def entropy(dataset, classifier):\n","    n = len(dataset.index)\n","    prob = 0\n","    class_dict = defaultdict(int)\n","    for datum in dataset.loc[:, classifier]:\n","        class_dict[datum] += 1\n","    for key in class_dict:\n","        p = (class_dict[key] / n)\n","        prob += (p *  np.log2(p))\n","\n","    return -1 * prob"]},{"cell_type":"markdown","metadata":{},"source":["### Misclassification error\n","\n","$1 - \\max\\limits_k p_k$"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-02-05T06:10:40.463300Z","iopub.status.busy":"2023-02-05T06:10:40.462877Z","iopub.status.idle":"2023-02-05T06:10:40.471273Z","shell.execute_reply":"2023-02-05T06:10:40.470226Z","shell.execute_reply.started":"2023-02-05T06:10:40.463267Z"},"trusted":true},"outputs":[],"source":["def misclassification_error(dataset, classifier):\n","    n = len(dataset.index)\n","    probs = []\n","    class_dict = defaultdict(int)\n","    for datum in dataset.loc[:, classifier]:\n","        class_dict[datum] += 1\n","    for key in class_dict:\n","        probs.append((class_dict[key] / n))\n","\n","    return 1 - max(probs)"]},{"cell_type":"markdown","metadata":{},"source":["## Tree creation"]},{"cell_type":"markdown","metadata":{},"source":["#### Defining helper functions for tree creation"]},{"cell_type":"code","execution_count":8,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-02-05T06:31:40.507502Z","iopub.status.busy":"2023-02-05T06:31:40.507119Z","iopub.status.idle":"2023-02-05T06:31:40.525585Z","shell.execute_reply":"2023-02-05T06:31:40.524406Z","shell.execute_reply.started":"2023-02-05T06:31:40.507470Z"},"trusted":true},"outputs":[],"source":["def split(dataset, attr, classifier, criteria: iGainType = iGainType.entropy):\n","    n = len(dataset.index)\n","    attr_dict = defaultdict(int)\n","    split_value = 0\n","    for datum in dataset.loc[:, attr]:\n","        attr_dict[datum] += 1\n","    for attr_value in attr_dict:\n","        # proportion\n","        weight = attr_dict[attr_value] / n\n","        # choose all examples with this attr value\n","        subset = dataset.loc[dataset[attr] == attr_value]\n","\n","        # impurity\n","        attr_v = 0\n","        if criteria == iGainType.gini:\n","            attr_v = gini_index(subset, classifier)\n","        elif criteria == iGainType.entropy:\n","            attr_v = entropy(subset, classifier)\n","        elif criteria == iGainType.misclass:\n","            attr_v = misclassification_error(subset, classifier)\n","            # handle here w weight\n","\n","        # info gain\n","        split_value += (weight * attr_v)\n","\n","    return split_value\n","\n","def split_values(dataset, classifier, attributes, criteria: iGainType = iGainType.entropy):\n","    split_vals = dict()\n","    for col in attributes:\n","        if col == classifier:\n","            continue\n","\n","        split_vals[col] = split(\n","            dataset, col, classifier, criteria)\n","\n","    return split_vals\n","\n","def majority_classification(data_set, classifier):\n","    classification_count = {}\n","    for datum in data_set.loc[:, classifier]:\n","        if datum not in classification_count:\n","            classification_count[datum] = 1\n","        else:\n","            classification_count[datum] += 1\n","    majority = max(classification_count.values())\n","    for key in classification_count.keys():\n","        if classification_count[key] == majority:\n","            return key\n","    return -1\n","\n","def best_attr(attr_split_values):\n","    argmin = min(attr_split_values.values())\n","    for k in attr_split_values.keys():\n","        if attr_split_values[k] == argmin:\n","            return k\n","    print('none found')\n","    return ''\n","\n","def homogeneous(data_set, classifier):\n","    class_set = {val for val in data_set.loc[:, classifier]}\n","    return len(class_set) == 1\n","\n","def classify(root: AttrNode, example: {}):\n","    while not root.is_leaf:\n","        ex_value = example[root.name]\n","        root = root.children[ex_value]\n","    return root.name"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-02-05T06:10:40.516527Z","iopub.status.busy":"2023-02-05T06:10:40.514717Z","iopub.status.idle":"2023-02-05T06:10:40.528605Z","shell.execute_reply":"2023-02-05T06:10:40.527304Z","shell.execute_reply.started":"2023-02-05T06:10:40.516468Z"},"trusted":true},"outputs":[],"source":["def create_decision_tree(data_set, classifier, attributes, examples, criteria: iGainType = iGainType.entropy):\n","    if homogeneous(data_set, classifier) or len(attributes) == 1:\n","        cls = majority_classification(data_set, classifier)\n","        return AttrNode(cls, 0, True)\n","\n","    attr_split_values = split_values(\n","        data_set,\n","        classifier,\n","        attributes,\n","        criteria\n","    )\n","    best_classifier = best_attr(attr_split_values)\n","    values = {val for val in examples.loc[:, best_classifier]}\n","    root = AttrNode(best_classifier, attr_split_values[best_classifier])\n","\n","    for value in values:\n","        value_subset = data_set.loc[data_set[best_classifier] == value]\n","        if len(value_subset.index) == 0:\n","            # no data records in subset, classification node\n","            # w/ value set to most common class at root node\n","            maj_class = majority_classification(data_set, classifier)\n","            child = AttrNode(maj_class, 0, True)\n","            root.children[value] = child\n","        else:\n","            # sub trees for remaining attributes\n","            root.children[value] = create_decision_tree(value_subset,\n","                                                        classifier,\n","                                                        attributes.values().remove(best_classifier),\n","                                                        examples)\n","    return root"]},{"cell_type":"markdown","metadata":{},"source":["### Train the model"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["training_data = train_df.loc[:, train_df.columns != 'id']\n","gini_root = create_decision_tree(training_data, 'class', training_data.columns, training_data, iGainType.gini)\n","entropy_root = create_decision_tree(training_data, 'class', training_data.columns, training_data, iGainType.entropy)\n","misclass_root = create_decision_tree(training_data, 'class', training_data.columns, training_data, iGainType.misclass)"]},{"cell_type":"markdown","metadata":{},"source":["### Predicition"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-02-05T06:41:13.673099Z","iopub.status.busy":"2023-02-05T06:41:13.672309Z","iopub.status.idle":"2023-02-05T06:41:13.750435Z","shell.execute_reply":"2023-02-05T06:41:13.749093Z","shell.execute_reply.started":"2023-02-05T06:41:13.673056Z"},"trusted":true},"outputs":[],"source":["validation_dict = validation_df.to_dict('records')\n","test_dict = test_df.to_dict('records')\n","\n","total_correct = 0\n","total = len(validation_dict)\n","\n","for prediction in validation_dict:\n","    actual_class = classify(misclass_root, prediction)\n","    expected_class = prediction['class']\n","    if actual_class == expected_class:\n","        total_correct += 1"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-02-05T06:41:32.855030Z","iopub.status.busy":"2023-02-05T06:41:32.854523Z","iopub.status.idle":"2023-02-05T06:41:32.862660Z","shell.execute_reply":"2023-02-05T06:41:32.861360Z","shell.execute_reply.started":"2023-02-05T06:41:32.854988Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["attribute=[name:odor, info_gain:0.026498874477435874], is_leaf=False\n","attribute=[name:odor, info_gain:0.08751921443519706], is_leaf=False\n","attribute=[name:odor, info_gain:0.013684210526315767], is_leaf=False\n","\n","correct=1425, total=1425, accuracy=1.0\n"]}],"source":["print(gini_root)\n","print(entropy_root)\n","print(misclass_root)\n","\n","accuracy = total_correct / total\n","print(f'\\ncorrect={total_correct}, total={total}, accuracy={accuracy}')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"vscode":{"interpreter":{"hash":"b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"}}},"nbformat":4,"nbformat_minor":4}
